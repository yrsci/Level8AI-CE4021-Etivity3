{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Yvonne Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 21208298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "*Notes to self:*\n",
    "\n",
    "Bayes' Theorem:\n",
    "$$ P(H|E) = \\frac{P(E|H)P(H)}{P(E)} = \\frac{P(E|H)P(H)}{P(E|H)P(H) + P(E|\\overline{H})P(\\overline{H})} $$\n",
    "\n",
    "Naive Bayes:\n",
    "$$ P(S|x_1, x_2, ..., x_n) \\approx \\frac{P(S)\\prod_{i=1}^n P(x_n|S)}{P(S)\\prod_{i=1}^n P(x_n|S) + P(H)\\prod_{i=1}^n P(x_n|H)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing data ###\n",
    "\n",
    "def word_set(msg_list):\n",
    "    '''\n",
    "    Function to create set of unique words from a\n",
    "    list of messages.\n",
    "    \n",
    "    Returns a set of unique strings.\n",
    "    '''\n",
    "    \n",
    "    def msg_lower(msg_list):\n",
    "        '''\n",
    "        Converts all characters in a list of messages\n",
    "        to lower case. Conversion is performed in-place.\n",
    "\n",
    "        Returns None.\n",
    "        '''\n",
    "        for i in range(0,len(msg_list)):\n",
    "            msg_list[i] = msg_list[i].lower()\n",
    "\n",
    "        return None\n",
    "    \n",
    "    if type(msg_list) is list:\n",
    "        msg_lower(msg_list)\n",
    "    \n",
    "    words = set()\n",
    "    for msg in msg_list:\n",
    "        for word in msg.split():\n",
    "            words.add(word)\n",
    "    \n",
    "    return words    \n",
    "\n",
    "\n",
    "### Naive Bayes classifier ### \n",
    "\n",
    "def naive_bayes(msg, previous_spam, previous_ham):\n",
    "    '''\n",
    "    Implementation of a naive Bayes classifier.\n",
    "    Takes a list of strings (msg) & classifies it as \n",
    "    either Spam or Ham, based on labelled training data\n",
    "    previous_spam & previous_ham.\n",
    "    \n",
    "    Subfunctions:\n",
    "        word_prob_dict(word_set_A, msg_list_A)\n",
    "        word_smooth_prob(w, msg_list_A)\n",
    "        marginal_prob(msg_list_A,msg_list_B)\n",
    "        dict_prod(word_set, prob_dict)\n",
    "        bayes_product(common_words, previous_words_A, \n",
    "            previous_msgs_A, marg_prob_A)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def word_prob_dict(word_set_A, msg_list_A):\n",
    "            '''\n",
    "            Returns a dictionary of word:probability pairs for the\n",
    "            words in the input word_set_A, based on the frequency of\n",
    "            that word in the training dataset (msg_list_A).\n",
    "            '''\n",
    "\n",
    "            def word_smooth_prob(w, msg_list_A):\n",
    "                '''\n",
    "                Calculate the Laplace smoothed probability for a word (w) to \n",
    "                appear in messages of type A, based on the frequency of w in \n",
    "                a training dataset of this type of message (msg_list_A). \n",
    "                In probability notation: P(w|A).\n",
    "                e.g. P(w|spam) = Laplace smoothed probability of w appearing in \n",
    "                spam messages.\n",
    "\n",
    "                1. Count how many messages in msg_list_A contain w & add 1. \n",
    "                2. Divide this by the number of messages in msg_list_A plus 2.\n",
    "\n",
    "                Returns a float.\n",
    "                '''\n",
    "                count = 0\n",
    "                for msg in msg_list_A:\n",
    "                    if w in msg.split():\n",
    "                        count += 1\n",
    "\n",
    "                return (float(count) + 1) / (float(len(msg_list_A)) + 2)\n",
    "\n",
    "            prob_dict = {}\n",
    "            for word in word_set_A:\n",
    "                prob_dict[word] = word_smooth_prob(word, msg_list_A)\n",
    "\n",
    "            return prob_dict    \n",
    "    \n",
    "    def marginal_prob(msg_list_A,msg_list_B):\n",
    "        '''\n",
    "        Calculates the marginal probability of messages of type A\n",
    "        (assuming only messages of type A or B are possible). \n",
    "        In probability notation: P(A)\n",
    "\n",
    "        The number of messages in msg_list_A is divided by the \n",
    "        total number of messages in msg_list_A & msg_list_B.\n",
    "\n",
    "        Returns a float.\n",
    "        '''\n",
    "        return float(len(msg_list_A) / (len(msg_list_A) + len(msg_list_B)))\n",
    "\n",
    "\n",
    "    def dict_prod(word_set, prob_dict):\n",
    "        '''\n",
    "        Computes the product of the probabilities of the words\n",
    "        in word_set, pulling these values from a dictionary of \n",
    "        word:probability pairs. If the word is not in the dictionary,\n",
    "        1 is returned as the value.\n",
    "        In probability notation: Product[P(w_i|A)] from i=1 to n.\n",
    "\n",
    "        '''\n",
    "        if len(word_set) > 0:\n",
    "            product = 1\n",
    "            for w in word_set:\n",
    "                product *= prob_dict.get(w,1)\n",
    "\n",
    "            return product\n",
    "\n",
    "        else: \n",
    "            return 0    \n",
    "    \n",
    "    \n",
    "    def bayes_product(common_words, previous_words_A, previous_msgs_A, marg_prob_A):\n",
    "        '''\n",
    "        Calculates a product term for use in the naive Bayes algorithm.\n",
    "        In probability notation: P(A)Product[P(x_i|A)] from i=1 to n.\n",
    "        '''\n",
    "        p_xi_A = dict_prod(common_words, word_prob_dict(previous_words_A, previous_msgs_A))\n",
    "\n",
    "        return p_xi_A * marg_prob_A    \n",
    "    \n",
    "    \n",
    "    ### Training classifier ###\n",
    "    \n",
    "    # Create sets of unique words per spam / ham list\n",
    "    previous_spam_words, previous_ham_words = word_set(previous_spam), word_set(previous_ham)\n",
    "    \n",
    "    # Build dictionaries of probabilities for each word per spam / ham list\n",
    "    word_prob_spam = word_prob_dict(previous_spam_words, previous_spam)\n",
    "    word_prob_ham = word_prob_dict(previous_ham_words, previous_ham)\n",
    "      \n",
    "    # Calculate the marginal probabilities for spam & ham\n",
    "    marg_prob_spam = marginal_prob(previous_spam, previous_ham)\n",
    "    marg_prob_ham = marginal_prob(previous_ham, previous_spam)  \n",
    "    \n",
    "    \n",
    "    ### Running classifier ###\n",
    "    \n",
    "    # Make a set of unique words common to msg & the training datasets\n",
    "    common_words = (set(msg.split())).intersection((previous_spam_words).union(previous_spam_words))\n",
    "    \n",
    "    \n",
    "    # Compute the probabilities P(x_i|S), P(x_i|H) for this message\n",
    "    p_xi_S = bayes_product(common_words, previous_spam_words, previous_spam, marg_prob_spam)\n",
    "    p_xi_H = bayes_product(common_words, previous_ham_words, previous_ham, marg_prob_ham) \n",
    "\n",
    "    \n",
    "    # Compute probability P(S|x_i) for this message & classify as 'SPAM' or 'HAM'\n",
    "    if p_xi_S != 0 and p_xi_S / (p_xi_S + p_xi_H) > 0.5:\n",
    "        return 'SPAM'\n",
    "    else:\n",
    "        return 'HAM' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run classifier on new messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message text: \"renew your password\"\n",
      "-> Classified as SPAM \n",
      "\n",
      "Message text: \"renew your vows\"\n",
      "-> Classified as SPAM \n",
      "\n",
      "Message text: \"benefits of our account\"\n",
      "-> Classified as HAM \n",
      "\n",
      "Message text: \"the importance of physical activity\"\n",
      "-> Classified as HAM \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run each message in the new_emails dataset through the classifier\n",
    "for msg in (new_emails['spam'] + new_emails['ham']):\n",
    "    print('Message text: \"{}\"'.format(msg))\n",
    "    print('-> Classified as', naive_bayes(msg, previous_spam, previous_ham),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
