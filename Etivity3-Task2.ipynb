{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Yvonne Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 21208298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "*Notes to self:*\n",
    "\n",
    "Bayes' Theorem:\n",
    "$$ P(H|E) = \\frac{P(E|H)P(H)}{P(E)} = \\frac{P(E|H)P(H)}{P(E|H)P(H) + P(E|\\overline{H})P(\\overline{H})} $$\n",
    "\n",
    "Naive Bayes:\n",
    "$$ P(S|x_1, x_2, ..., x_n) \\approx \\frac{P(S)\\prod_{i=1}^n P(x_n|S)}{P(S)\\prod_{i=1}^n P(x_n|S) + P(H)\\prod_{i=1}^n P(x_n|H)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes classifier ### \n",
    "\n",
    "def naive_bayes(msg, previous_spam, previous_ham, neutral_words):\n",
    "    '''\n",
    "    Implementation of a naive Bayes classifier.\n",
    "    Classifies a list of strings (msg) as Spam or Ham, based \n",
    "    on labelled training data previous_spam & previous_ham.\n",
    "    \n",
    "    Subfunctions:\n",
    "        word_set(msg_list)\n",
    "        word_prob_dict(word_set_A, msg_list_A)\n",
    "        word_smooth_prob(w, msg_list_A)\n",
    "        marginal_prob(msg_list_A,msg_list_B)\n",
    "        dict_prod(word_set, prob_dict)\n",
    "        bayes_product(common_words, previous_words_A, \n",
    "            previous_msgs_A, marg_prob_A)\n",
    "    Input:  \n",
    "        msg - message to be classified\n",
    "        previous_spam - list of labelled spam messages\n",
    "        previous_ham - list of labelled ham messages\n",
    "    Returns:\n",
    "        spamicity - float; probability that msg is spam\n",
    "        string - SPAM or HAM depending on spamicity value\n",
    "    '''\n",
    "    \n",
    "    def word_set(msg_list):\n",
    "        '''\n",
    "        Function to create set of unique words from a\n",
    "        list of messages.\n",
    "\n",
    "        Input: List of messages as lists of strings\n",
    "        Returns: Set of unique strings from Input, in lower case\n",
    "        '''\n",
    "        words = set()\n",
    "        for msg in msg_list:\n",
    "            for word in msg.split():\n",
    "                words.add(word.lower())\n",
    "\n",
    "        return words\n",
    "    \n",
    "    \n",
    "    def word_prob_dict(word_set_A, msg_list_A):\n",
    "            '''\n",
    "            Returns a dictionary of word:probability pairs for the\n",
    "            words in the input word_set_A, based on the frequency of\n",
    "            that word in the training dataset (msg_list_A).\n",
    "            \n",
    "            Subfunction:\n",
    "                word_smooth_prob(w, msg_list_A)\n",
    "                \n",
    "            Input:\n",
    "                word_set_A: Set of unique words from dataset A (set)\n",
    "                msg_list_A: List of messages from dataset A (list)\n",
    "            Returns:\n",
    "                prob_dict: Dictionary of word:probability pairs (dict)\n",
    "            '''\n",
    "\n",
    "            def word_smooth_prob(w, msg_list_A):\n",
    "                '''\n",
    "                Calculate the Laplace smoothed probability for a word (w) to \n",
    "                appear in messages of type A, based on the frequency of w in \n",
    "                a training dataset of this type of message (msg_list_A). \n",
    "                In probability notation: P(w|A).\n",
    "                e.g. P(w|spam) = Laplace smoothed probability of w appearing in \n",
    "                spam messages.\n",
    "\n",
    "                1. Count how many messages in msg_list_A contain w & add 1. \n",
    "                2. Divide this by the number of messages in msg_list_A plus 2.\n",
    "                \n",
    "                Input:\n",
    "                    w: Word to calculate smoothed probability for\n",
    "                    msg_list_A: List of messages from dataset A\n",
    "                Returns: \n",
    "                    prob_dict: Probability of w being in msg_list_A (float)\n",
    "                '''\n",
    "                count = 0\n",
    "                for msg in msg_list_A:\n",
    "                    if w in msg.split():\n",
    "                        count += 1\n",
    "\n",
    "                return (float(count) + 1) / (float(len(msg_list_A)) + 2)\n",
    "\n",
    "            prob_dict = {word:word_smooth_prob(word, msg_list_A) for word in word_set_A} \n",
    "            \n",
    "            return prob_dict    \n",
    "    \n",
    "    def marginal_prob(msg_list_A,msg_list_B):\n",
    "        '''\n",
    "        Calculates the marginal probability of messages of type A\n",
    "        (assuming only messages of type A or B are possible). \n",
    "        In probability notation: P(A)\n",
    "\n",
    "        The number of messages in msg_list_A is divided by the \n",
    "        total number of messages in msg_list_A & msg_list_B.\n",
    "\n",
    "        Input:\n",
    "            msg_list_A: List of messages from dataset A (list)\n",
    "            msg_list_B: List of messages from dataset B (list)\n",
    "        Returns: \n",
    "            Marginal probability for A (float)\n",
    "        '''\n",
    "        return float(len(msg_list_A) / (len(msg_list_A) + len(msg_list_B)))\n",
    "\n",
    "\n",
    "    def dict_prod(word_set, prob_dict):\n",
    "        '''\n",
    "        Computes the product of the probabilities of the words\n",
    "        in word_set, pulling these values from a dictionary of \n",
    "        word:probability pairs. If the word is not in the dictionary,\n",
    "        1 is returned as the value.\n",
    "        In probability notation: Product[P(w_i|A)] from i=1 to n.\n",
    "        \n",
    "        Input:\n",
    "            word_set: Set of unique words (set)\n",
    "            prob_dict: Dictionary of word:probability pairs (dict)\n",
    "        Returns:\n",
    "            product: If word_set is not empty, product of probabilities \n",
    "                of all the words in word_set (float)\n",
    "            0: If word_set is empty (int)\n",
    "        '''\n",
    "        if len(word_set) > 0:\n",
    "            product = 1\n",
    "            for w in word_set:\n",
    "                product *= prob_dict.get(w,1)\n",
    "\n",
    "            return product\n",
    "\n",
    "        else: \n",
    "            return 0    \n",
    "    \n",
    "    \n",
    "    def bayes_product(common_words, word_prob_dict_A, marg_prob_A):\n",
    "        '''\n",
    "        Calculates a product term for use in the naive Bayes algorithm.\n",
    "        In probability notation: P(A)Product[P(x_i|A)] from i=1 to n.\n",
    "        \n",
    "        Inputs:\n",
    "            common_words: Set of unique words in common between msg & \n",
    "            all training datasets (set)\n",
    "            word_prob_dict_A: Dictionary of word:probability pairs for \n",
    "            words in dataset A (dict)\n",
    "            marg_prob_A: Marginal probability for A (float)\n",
    "        Returns:\n",
    "            Product of probabilities of all words in common_words & \n",
    "            marginal probability of A (float)\n",
    "        '''\n",
    "        p_xi_A = dict_prod(common_words, word_prob_dict_A)\n",
    "        \n",
    "        return p_xi_A * marg_prob_A    \n",
    "    \n",
    "    \n",
    "    ### Training classifier ###\n",
    "    \n",
    "    # Create sets of unique words per spam / ham list; strip out neutral words\n",
    "    previous_spam_words = word_set(previous_spam).difference(neutral_words)\n",
    "    previous_ham_words = word_set(previous_ham).difference(neutral_words)\n",
    "    \n",
    "    # Build dictionaries of probabilities for each word per spam / ham list\n",
    "    word_prob_spam = word_prob_dict(previous_spam_words.union(previous_ham_words), previous_spam)\n",
    "    word_prob_ham = word_prob_dict(previous_spam_words.union(previous_ham_words), previous_ham)\n",
    "    \n",
    "    # Calculate the marginal probabilities for spam & ham\n",
    "    marg_prob_spam = marginal_prob(previous_spam, previous_ham)\n",
    "    marg_prob_ham = marginal_prob(previous_ham, previous_spam)  \n",
    "    \n",
    "    \n",
    "    ### Running classifier ###\n",
    "    \n",
    "    # Make a set of unique words common to msg & the training datasets\n",
    "    common_words = (set(msg.split())).intersection(previous_spam_words.union(previous_ham_words))\n",
    "    \n",
    "    # Compute the probabilities P(x_i|S), P(x_i|H) for this message\n",
    "    p_xi_S = bayes_product(common_words, word_prob_spam, marg_prob_spam)\n",
    "    p_xi_H = bayes_product(common_words, word_prob_ham, marg_prob_ham) \n",
    "    \n",
    "    # Compute probability P(S|x_i) for this message\n",
    "    if p_xi_H != 0:\n",
    "        spamicity = p_xi_S / (p_xi_S + p_xi_H)\n",
    "    else:\n",
    "        spamicity = 0\n",
    "    \n",
    "    # Classify as 'SPAM' or 'HAM'\n",
    "    if spamicity > 0.5:\n",
    "        return spamicity, 'SPAM'\n",
    "    else:\n",
    "        return spamicity, 'HAM' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = {'the', 'of', 'and'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run classifier on new messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message text: renew your password\n",
      "Spamicity = 98.30%\n",
      "-> Classified as SPAM\n",
      "\n",
      "Message text: renew your vows\n",
      "Spamicity = 93.54%\n",
      "-> Classified as SPAM\n",
      "\n",
      "Message text: benefits of our account\n",
      "Spamicity = 21.13%\n",
      "-> Classified as HAM\n",
      "\n",
      "Message text: the importance of physical activity\n",
      "Spamicity = 2.18%\n",
      "-> Classified as HAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all messages in the new_emails dataset\n",
    "for msg in (new_emails['spam'] + new_emails['ham']):\n",
    "    \n",
    "    # Run message through the classifier\n",
    "    spamicity, classif = naive_bayes(msg, previous_spam, previous_ham, neutral_words)\n",
    "    \n",
    "    # Print the output\n",
    "    print('Message text: {}'.format(msg))\n",
    "    print('Spamicity = {:0.2%}'.format(spamicity))\n",
    "    print('-> Classified as {}\\n'.format(classif))\n",
    "    \n",
    "    # Learn from the latest classification between iterations\n",
    "    if msg not in (previous_spam + previous_ham):\n",
    "        if classif == 'SPAM':\n",
    "            previous_spam.append(msg)\n",
    "        elif classif == 'HAM':\n",
    "            previous_ham.append(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
